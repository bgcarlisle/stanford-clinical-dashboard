methods_page <- tabPanel(
    "Methods", value = "tabMethods",
    h1("Methods"),
    
    h4(HTML('This is a proof-of-principle dashboard for Open Science in clinical research at German University
    Medical Centers (UMCs). Please note that the data presented in this dashboard is still under
    development and should not be used &#8211 solely or in part &#8211 to compare UMCs or inform policy decisions.
    You can find more information on our methods for individual metrics by extending the panels below. You
    can also find a list of tools used for data collection at the bottom of this page.')),
    
    h3("Identification of clinical trials"),
    bsCollapse(id = "methodsPanels_IdentificationTrials",
               bsCollapsePanel(strong("Identification of clinical trials"),
                               p(HTML("IntoValue study.")),
                               value = "methodsPanels_IdentificationTrials",
                               style = "default")),
    
    h3("Trial Registration"),
    bsCollapse(id = "methodsPanels_TrialRegistration",
               methods_panel("Prospective registration",
                             
                             "This metric measures if the clinical trials are registered before the
                        start date of the study, according to the information given on ClinicalTrials.gov and DRKS.
                        The idea of prospective registration of studies is to make the trial specifications,
                        including primary and secondary outcomes, publicly available before study start.
                        Prospective registration adds transparency, helps protect against outcome switching.",
                             
                             "We used the same methods as for the timely reporting metric to identify trials
                             from UMCs. To assess if a study has been prospectively registered, we compare
                        the date the study was first submitted to the registry with the
                        start date given in the registry. As some of the earlier dates in the database
                        only stated the month but not the exact day and to account for other possible delays
                        we chose a conservative estimate of prospective registration and allow for a delay
                        between start and registration date of up to 60 days.",
                             
                             "Like in the case of the summary results metric, we only focused on the
                        ClinicalTrials.gov and DRKS while there are other available registries as well.
                        Also, we rely on the information on ClinicalTrials.gov and DRKS being accurate."),
               
               methods_panel("Reporting of Trial Registration Number (TRN)",
                             
                             HTML("Reporting of clinical trial registration numbers in related publications
                             facilitates transparent linkage between registration and publication and enhances
                             the value of the individual parts towards more responsible biomedical research
                             and evidence-based medicine. The <a 
                             href=https://www.sciencedirect.com/science/article/pii/S0140673607618352?via%3Dihub>
                             Consolidated Standards of Reporting Trials (CONSORT)</a>
                             as well as the <a href=http://www.icmje.org/recommendations/>ICMJE Recommendations
                             for the Conduct, Reporting, Editing, and Publication of Scholarly Work in Medical
                             Journals</a> call for reporting <i>&#39trial registration number and name of the
                             trial register&#39</i> in both the full-text and abstract."),
                             
                             HTML('We developed an <a href="https://github.com/maia-sh/ctregistries">open source R
                                  package</a> for the detection and classification of clinical trial registration
                                  numbers. Our regular-expression-based algorithm searches text strings for
                                  matches to TRN patterns for all PubMed-indexed and ICTRP-network registries.
                                  In a first step, we filtered the publication dataset for PubMed-classified
                                  human clinical trials. Then, we used the aforementioned package to detect
                                  and classify trial registration numbers in the PubMed secondary identifier
                                  metadata and abstract.'),
                             
                             HTML("Our algorithm does not distinguish true TRNs that do not resolve to a registration.
                             Moreover, the algorithm does not determine whether the TRN is reported as a registration
                                  for the publication&#39s study (i.e., clinical trial result) or is otherwise
                                  mentioned (i.e., in a review, reference to other clinical trials, etc.)"))),
    h3("Trial Reporting"),
    bsCollapse(id = "methodsPanels_TrialReporting",
               methods_panel("Summary results reporting in EUCTR",
                             
                             "This metric measures how many clinical trials registered in the
                        EU Clinical Trials Register (EUCTR) that are due to report their results have already
                        done so. A trial is due to report its results 12 month after trial completion.
                        Clinical trials are expensive and have often many contributing patients.
                        A fast dissemination of the trial results is crucial to make the evidence gained
                        in those trials available. The World Health organization recommends publishing
                        clinical trial results within one year after the end of a study.",
                             
                             HTML('The data were retrieved for all UMCs included in this proof-of-principle
                             dataset from the
                        <a href="https://eu.trialstracker.net">EU Trials Tracker</a> by the EBM DataLab.'),
                             
                             "The EU Trials Tracker does not measure for how long the trials have been due."),
               
               methods_panel("Results reporting (2-year and 5-year reporting)",
                             
                             "This metric measures how many clinical trials registered in ClinicalTrials.gov
                        or DRKS reported their results as either a journal publication or as summary
                        results on the registry within 2 and 5 years after trial completion. Trials
                        completed between 2009 and 2017 were considered.
                        A fast dissemination of the trial results is crucial to make the evidence gained
                        in those trials available. The World Health organization recommends publishing
                        clinical trial results within one year after the end of a study.",
                             
                             HTML('ClinicalTrials.gov and DRKS.de were searched for studies with one of the UMCs
                             as the responsible party/sponsor or with a principal investigator from one of the
                             UMCs. A manual search for published results was done, searching the
                        registry, PubMed and Google. When calculating the time to publication, we only
                        considered trials where we could track the full timeframe since completion.
                        The results were previously
                        published as part of the <a href="https://s-quest.bihealth.org/intovalue/">IntoValue study</a>.
                        Detailed methods can be found under
                        <a href="https://doi.org/10.1101/467746">https://doi.org/10.1101/467746</a>.'),
                             "Some detected publications might be missed in the manual search
                        procedure as we only searched a limited number of scientific databases and did not
                        contact the responsible parties. Furthermore, we did not include observational clinical
                        studies in our sample. Additionally, we might overestimate the time to publication
                        for some studies as we stopped the manual search after the first detected publication.")),

    hr(),
    h3("Open Access"),
    bsCollapse(id = "methodsPanels_OpenAccess",
               
               methods_panel("Open Access",
                             
                             "A lot of valuable research, much of which is publicly funded, is hidden
                             behind paywalls. Open Access (OA) makes research articles available online,
                             free of charge and most copyright barriers. The free, public availability of
                             research articles accelerates and broadens the dissemination of research discoveries.
                             OA also enables greater visibility of research and makes it easier to build
                             on existing knowledge. Research funders are increasingly encouraging OA
                             to maximise the value and impact of research discoveries.",
                             
                             HTML('Using the obtained list of institutional publications, we queried the
                        Unpaywall database via its <a href="https://unpaywall.org/products/api">API</a>
                        to obtain information on the OA status of the publications. Unpaywall is today the
                        most comprehensive database of OA information on research articles. It can be queried
                        using publication DOIs. Publications can have different OA statuses which are
                        color-coded. Gold OA denotes a publication in an OA journal. Green OA denotes a
                        freely available repository version. Hybrid OA denotes an OA publication in a journal
                        which offers both a subscription based model as well as an OA option. Bronze OA denotes
                        a publication which is freely available on the journal page, but without a clear open
                        license. These can be articles in a non-OA journal which have been made available
                        voluntarily by the journal, but which might at some stage lose their OA status again.
                        Thus, we only consider the OA categories gold, green and hybrid for this dashboard.
                        As one publication can have several OA versions (e.g. a gold version in an OA journal
                        as well as a green version in a repository), we define a hierarchy for the OA categories
                        and for each publication only assign the OA category with the highest priority. We use
                        a hierarchy of gold - hybrid - green (journal version before repository version), as
                        also implemented in the Unpaywall database itself.
                        After querying the Unpaywall API for all publication DOIs, we group
                        the results by OA status.
                        <br>
                        <br>One important point that has to be considered with OA data is that
                        the OA percentage is not a fixed number, but changes over time. This is due to the fact
                        that repository versions are often made available with a delay, such that the OA
                        percentage for a given year typically rises retrospectively. Thus, the point in time
                        at which the OA status is retrieved is important for the OA percentage. The current
                        OA data was retrieved using (with <a href="https://github.com/NicoRiedel/unpaywallR">
                             UnpaywallR</a>) on: 28/02/2021.'),
                             
                             "Unpaywall only stores information for publications which have a DOI assigned by
                        Crossref. Articles without a Crossref DOI have to be excluded from the OA analysis."),
               
               methods_panel("Potential Green Open Access",
                             
                             "This metric measures how many paywalled publications with the potential for green OA
                             have been made openly accessible in a repository. In many cases, journal or publisher
                             self-archiving policies allow researchers to make the accepted version of their
                             publication openly accessible in a repository after an embargo period.",
                             
                             HTML('We queried the Unpaywall API (with <a href="https://github.com/NicoRiedel/unpaywallR">
                             UnpaywallR</a>) and applied the following hierarchy to identify 
                             publications only accessible via green OA: gold - hybrid - bronze - green. To identify
                             paywalled publications with the potential for green OA, we filtered our dataset for
                             paywalled publications and queried the
                             <a href="https://shareyourpaper.org/permissions/about#api">
                             Shareyourpaper.org permissions API</a> (Open Access Button) to obtain article-level
                             self-archiving permissions based on journal and/or publisher policies. Publications
                             were considered to have the potential for green OA if an authoritative permission
                             was found for archiving the accepted version of the publication in an institutional
                                  repository.'),
                             
                             "This measure depends on the Shareyourpaper.org permissions database being up-to-date. We
                             only included publications which have an authoritative permission in the Shareyourpaper.org
                             database. The date at which a publication can be made openly accessible via self-archiving
                             depends on the publication date and the length of the embargo (if any). Therefore, the
                             number of potential green OA research articles will change over time. The Shareyourpaper
                             permissions API was queried on 28/02/2021. The Unpaywall database was queried on 11/03/2021.")),
                   
    h3("Tools used for data collection"),
    helpText(HTML('<a href="https://github.com/NicoRiedel/unpaywallR"> UnpaywallR </a>')),
    helpText(HTML('<a href="https://shareyourpaper.org/permissions/about">
                  ShareYourPaper permissions checker API</a> from the Open Access Button')),
    helpText(HTML('<a href="https://github.com/maia-sh/ctregistries"> ctregistries R package </a>')),
    helpText(HTML('<a href="https://eu.trialstracker.net/">EU Trials Tracker </a>'))
)


## Tooltips for Open Science metrics

openaccess_tooltip <- strwrap("The Open Access metric shows the percentage of research publications that are published as Open Access (OA) articles. Gold OA denotes publication in a pure OA journal. Green OA denotes a freely available repository version. Hybrid OA denotes an OA publication in a journal which offers both a subscription based model as well as an Open Access option. Bronze OA denotes a publication which is freely available on the journal page, but without a clear open license. Closed articles are not freely available. For some articles no Open Access information was available.") %>%
    paste(collapse = " ")

opendata_tooltip <- strwrap("This metric measures the percentage of screened publications that state
                                that they shared their research data. We used the text-mining algorithm
                                ODDPub to identify publications which share research data.
                                Openly shared data makes research more transparent, as research findings can
                                be reproduced. Additionally, shared datasets can be reused and combined by other
                            scientists to answer new research questions.") %>%

paste(collapse = " ")

opencode_tooltip <- strwrap("The Open Code metric measures the percentage of screened publications
                             that state that they shared their analysis code. We used the text-mining
                             algorithm ODDPub to identify publications which share analysis code.
                            Like openly shared data, Open Code makes research more transparent, as research
                            findings can be reproduced.") %>%

paste(collapse = " ")

## Tooltips for Clinical Trials metrics

trn_tooltip <- strwrap("This metric measures how many clinical trials report a trial registration number (TRN) in the abstract and in the
                        full-text of the publication. Reporting of clinical trial registration
                        numbers in related publications facilitates transparent linkage between registration and
                        publication. The CONSORT as well as the ICMJE Recommendations for the Conduct, Reporting,
                        Editing, and Publication of Scholarly Work in Medical Journals call for reporting
                        <i>&#39trial registration number and name of the trial register&#39</i> in both the
                       full-text and abstract.") %>%

paste(collapse = " ")


linkage_tooltip <- strwrap("This metric measures how many clinical trial registry entries provide links to the journal publication of the primary outcome for the trial in question.")

lim_linkage_tooltip <- strwrap("This metric only captures clinical trial registry entries that link to the final, full-text publication of the primary outcome for the trial in question.")

allumc_linkage_tooltip <- strwrap("This metric measures how many clinical trial registry entries provide links to the journal publication of the primary outcome for the trial in question.")

lim_allumc_linkage_tooltip <- strwrap("This metric only captures clinical trial registry entries that link to the final, full-text publication of the primary outcome for the trial in question.")

sumres_tooltip <- strwrap("This metric measures how many clinical trials registered in the
                        EU Clinical Trials Register that are due to report their results have already
                        done so. A trial is due to report its results 12 month after trial completion.
                        The data were retrieved from the EU Trials Tracker by the EBM DataLab
                        (eu.trialstracker.net). Clinical trials are expensive and have often many contributing
                        patients. A timely dissemination of the trial results is crucial to make the evidence
                        gained in those trials available. The World Health organization recommends publishing
                        clinical trial results within one year after the end of a study.") %>%
    
paste(collapse = " ")

prereg_tooltip <- strwrap("This metric measures if the clinical trials are registered before the
                        start date of the study, according to the information given on ClinicalTrials.gov or DRKS.de.
                        The idea of prospective registration of studies is to make the trial specifications,
                        including primary and secondary outcomes, publicly available before study start.
                        Prospective registration adds transparency, helps protect against outcome switching.") %>%
    
paste(collapse = " ")

timpub_tooltip2 <- strwrap("This metric measures how many clinical trials registered on ClinicalTrials.gov or DRKS.de
                        reported their results either as a journal publication or as summary results on the
                        trials registry within 2 years after completion. Trials completed between 2009
                        and 2017 were considered. The results were previously published as part of the
                        IntoValue study (https://s-quest.bihealth.org/intovalue/). Clinical trials are expensive
                        and often have many contributing patients. A fast dissemination of the trial results
                        is crucial to make the evidence gained in those trials available. The World Health
                        organization recommends publishing clinical trial results within one year after the
                        end of a study.") %>%

    paste(collapse = " ")

timpub_tooltip5 <- strwrap("This metric measures how many clinical trials registered on ClinicalTrials.gov or DRKS.de
                        reported their results either as a journal publication or as summary results on the
                        trials registry within 5 years after completion. Trials completed between 2009
                        and 2017 were considered. The results were previously published as part of the
                        IntoValue study (https://s-quest.bihealth.org/intovalue/). Clinical trials are expensive
                        and often have many contributing patients. A fast dissemination of the trial results
                        is crucial to make the evidence gained in those trials available. The World Health
                        organization recommends publishing clinical trial results within one year after the
                        end of a study.") %>%

paste(collapse = " ")

## Tooltips for Robustness metrics

randomization_tooltip <- strwrap("This metric measures how many animal studies report a statement on
                            randomization of subjects into groups. Animal studies were identified using a
                            previously published PubMed search filter. Reporting of randomization was evaluated
                            with SciScore, an automated tool which evaluates research articles based on their
                            adherence to rigour and reproducibility criteria. Only animal studies in English
                            and contained in the PubMed Central corpus (for which we have SciScore data) could
                            be analyzed.") %>%
    
paste(collapse = " ")


blinding_tooltip <- strwrap("This metric measures how many animal studies report a statement on whether
                            investigators were blinded to group assignment and/or outcome assessment. Animal
                            studies were identified using a previously published PubMed search filter. Reporting
                            of blinding was evaluated with SciScore, an automated tool which evaluates research
                            articles based on their adherence to rigour and reproducibility criteria. Only animal studies in English
                            and contained in the PubMed Central corpus (for which we have SciScore data) could
                            be analyzed.") %>%

paste(collapse = " ")


power_tooltip <- strwrap("This metric measures how many animal studies report a statement on sample size
                         calculation. Animal studies were identified using a previously published PubMed search
                         filter. Reporting of sample size calculation was evaluated with SciScore, an automated
                         tool which evaluates research articles based on their adherence to rigour and
                         reproducibility criteria. Only animal studies in English
                            and contained in the PubMed Central corpus (for which we have SciScore data) could
                            be analyzed.") %>%
    
paste(collapse = " ")

greenopenaccess_tooltip <- strwrap("This metric measures how many paywalled publications with the potential for green OA
                             have been made openly accessible in a repository. In many cases, journal or publisher
                             self-archiving policies allow researchers to make the accepted version of their
                             publication openly accessible in a repository after an embargo period. We queried the
                             Shareyourpaper.org permissions API (Open Access Button) to obtain article-level
                             self-archiving permissions. Publications were considered to have the potential
                             for green OA if an authoritative permission was found for archiving the accepted
                             version of the publication in an institutional repository.") %>%
paste(collapse = " ")
                                        # iacuc_tooltip <- strwrap("This metric measures how many animal studies report an Institutional animal care and
#                          use committee statement.") %>%
#     
# paste(collapse = " ")

lim_randomization_tooltip <- strwrap("We did not test the sensitivity and precision of the approach used to identify animal studies in our dataset, nor the data obtained from SciScore. Moreover, we do not have SciScore data for all studies in our publication set. Finally, randomization may not always apply, especially in early-stage exploratory research (hypothesis-generating experiments).")
lim_blinding_tooltip <- strwrap("We did not test the sensitivity and precision of the approach used to identify animal studies in our dataset, nor the data obtained from SciScore. Moreover, we do not have SciScore data for all studies in our publication set. Finally, blinding may not always apply, especially in early-stage exploratory research (hypothesis-generating experiments).")
lim_power_tooltip <- strwrap("We did not test the sensitivity and precision of the approach used to identify animal studies in our dataset, nor the data obtained from SciScore. Moreover, we do not have SciScore data for all studies in our publication set. Finally, sample size calculation may not always apply, especially in early-stage exploratory research (hypothesis-generating experiments).")
lim_sumres_tooltip <- strwrap("While the EU Clinical Trials Register is one of the most important European trial registries, it is not the only available registry. There are other registries such as ClinicalTrials.gov. or the German Clinical Trials Registry, which are not considered here. Additionally, the EU Trials Tracker does not measure for how long the trials have been due. Finally, we only considered the latest data available in the EU Trials Tracker. We plan to include historic data in the future.")
lim_prereg_tooltip <- strwrap("We focused on ClinicalTrials.gov and DRKS.de while there are other available registries as well. Also, we rely on the information on ClinicalTrials.gov and DRKS.de being accurate.")
lim_timpub_tooltip2 <- strwrap("Some detected publications might be missed in the manual search procedure as we only searched a limited number of scientific databases and did not contact the responsible parties. Furthermore, we did not include observational clinical studies in our sample. Additionally, we might overestimate the time to publication for some studies as we stopped the manual search after the first detected publication.")
lim_timpub_tooltip5 <- strwrap("Some detected publications might be missed in the manual search procedure as we only searched a limited number of scientific databases and did not contact the responsible parties. Furthermore, we did not include observational clinical studies in our sample. Additionally, we might overestimate the time to publication for some studies as we stopped the manual search after the first detected publication.")
lim_trn_tooltip <- strwrap(HTML("We identified human clinical trials based on the following search term in PubMed: &#39clinical trial&#39[pt] NOT (animals [mh] NOT humans [mh]). However, we have not tested (1) the sensitivity of this PubMed search term; (2) the precision of this search term. Our algorithm does not distinguish true TRNs that do not resolve to a registration. Our algorithm does not determine whether the TRN is reported as a registration for the publication&#39s study."))

lim_openaccess_tooltip <- strwrap("Unpaywall only stores information for publications which have a DOI assigned by Crossref. Articles without a Crossref DOI have to be excluded from the OA analysis. The OA percentage is not a fixed number, but changes over time as some publications become accessible with a delay. The current data was retrieved on: 28/02/2021.")
lim_greenopenaccess_tooltip <- strwrap("Not all publications had an authoritative permission when the query was made. This metric relies on the permissions database being up-to-date. Moreover, the date at which a publication can be made openly accessible via self-archiving depends on the publication date and the length of the embargo (if any). Therefore, the number of potential green OA publications will change over time. The Shareyourpaper.org permissions API was queried on 28/02/2021.")
lim_opendata_tooltip <- strwrap("This analysis could only be performed on articles for which we could access the full text. ODDPub only finds ~75% of all Open Data publications and finds false positive cases (no manual check of the results). ODDPub also does not verify that the dataset is available and whether it fulfills our definition of Open Data. Finally, Open Data is not relevant for all publications.")
lim_opencode_tooltip <- strwrap("This analysis could only be performed on articles for which we could access the full text. ODDPub only finds ~75% of all publications with Open Code and finds false positive cases (no manual check of the results). ODDPub also does not verify that the code is available and whether it fulfills our definition of Open Code Finally, Open Code is not relevant for all publications.")
lim_allumc_openaccess_tooltip <- strwrap("Unpaywall only stores information for publications which have a DOI assigned by Crossref. Articles without a Crossref DOI have to be excluded from the OA analysis. The OA percentage is not a fixed number, but changes over time as some publications become accessible with a delay. The current data was retrieved on: 28/02/2021.")
lim_allumc_opendata_tooltip <- strwrap("This analysis could only be performed on articles for which we could access the full text. ODDPub only finds ~75% of all Open Data publications and finds false positive cases (no manual check of the results). ODDPub also does not verify that the dataset is available and whether it fulfills our definition of Open Data. Finally, Open Data is not relevant for all publications.")
lim_allumc_opencode_tooltip <- strwrap("This analysis could only be performed on articles for which we could access the full text. ODDPub only finds ~75% of all publications with Open Code and finds false positive cases (no manual check of the results). ODDPub also does not verify that the code is available and whether it fulfills our definition of Open Code Finally, Open Code is not relevant for all publications.")

lim_allumc_clinicaltrials_trn_tooltip <- strwrap("We identified human clinical trials based on the following search term in PubMed: 'clinical trial'[pt] NOT (animals [mh] NOT humans [mh]). However, we have not tested (1) the sensitivity of this PubMed search term (i.e., what proportion of true clinical trial publications are detected?); (2) the precision of this search term (i.e, what proportion of detected publications are not true clinical trials publications?). Furthermore, our algorithm does not distinguish true TRNs that do not resolve to a registration. Finally, the algorithm does not determine whether the TRN is reported as a registration for the publication's study (i.e., clinical trial result) or is otherwise mentioned (i.e., in a review, reference to other clinical trials, etc.)")
lim_allumc_clinicaltrials_sumres_tooltip <- strwrap("While the EU Clinical Trials Register is one of the most important European trial registries, it is not the only available registry. There are other registries such as ClinicalTrials.gov. or the German Clinical Trials Registry, which are not considered here. Additionally, the EU Trials Tracker does not measure for how long the trials have been due. Finally, we only considered the latest data available in the EU Trials Tracker. We plan to include historic data in the future.")
lim_allumc_clinicaltrials_prereg_tooltip <- strwrap("Like in the case of the summary results metric, we only focused on the ClinicalTrials.gov while there are other available registries as well. Also, we rely on the information on ClinicalTrials.gov being accurate.")
lim_allumc_clinicaltrials_timpub_tooltip <- strwrap("Some detected publications might be missed in the manual search procedure as we only searched a limited number of scientific databases and did not contact the responsible parties. Furthermore, we did not include observational clinical studies in our sample. Additionally, we might overestimate the time to publication for some studies as we stopped the manual search after the first detected publication.")
lim_allumc_clinicaltrials_timpub_tooltip5a <- strwrap("Some detected publications might be missed in the manual search procedure as we only searched a limited number of scientific databases and did not contact the responsible parties. Furthermore, we did not include observational clinical studies in our sample. Additionally, we might overestimate the time to publication for some studies as we stopped the manual search after the first detected publication.")
lim_allumc_animal_rando_tooltip <- strwrap("We did not test the sensitivity and precision of the approach used to identify animal studies in our dataset, nor the data obtained from SciScore. Moreover, we do not have SciScore data for all studies in our publication set. Finally, randomization may not always apply, especially in early-stage exploratory research (hypothesis-generating experiments).")
lim_allumc_animal_blind_tooltip <- strwrap("We did not test the sensitivity and precision of the approach used to identify animal studies in our dataset, nor the data obtained from SciScore. Moreover, we do not have SciScore data for all studies in our publication set. Finally, blinding may not always apply, especially in early-stage exploratory research (hypothesis-generating experiments).")
lim_allumc_animal_power_tooltip <- strwrap("We did not test the sensitivity and precision of the approach used to identify animal studies in our dataset, nor the data obtained from SciScore. Moreover, we do not have SciScore data for all studies in our publication set. Finally, sample size calculation may not always apply, especially in early-stage exploratory research (hypothesis-generating experiments).")
lim_allumc_greenoa_tooltip <- strwrap("")
